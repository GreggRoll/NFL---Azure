{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2609e705350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from logger import setup_logger\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import hashlib\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import random\n",
    "import sqlite3\n",
    "from utils.helper_functions import *\n",
    "from datetime import datetime, timedelta\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "def get_data(start_date, end_date):\n",
    "    # Configure ChromeOptions for headless browsing\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")  # This line can be important in certain environments\n",
    "    options.set_capability('goog:loggingPrefs', {'browser': 'SEVERE'})\n",
    "    # Initialize the Chrome WebDriver with the specified options\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(\"https://www.bovada.lv/sports/football/nfl\")\n",
    "    # wait for the page to load\n",
    "    time.sleep(10)\n",
    "    driver.implicitly_wait(10)\n",
    "    # get the HTML source\n",
    "    html = driver.page_source\n",
    "    # create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    data = []\n",
    "    sections = soup.find_all(\"section\", {\"class\":\"coupon-content more-info\"})#soup.find_all(\"section\", {\"class\":\"coupon-content more-info\"})\n",
    "    for game in sections:\n",
    "        try:\n",
    "            item = str(game).split('>')\n",
    "            info = [x.split('<')[0].strip() for x in item if not x.startswith(\"<\")]\n",
    "            data.append(info)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"Home Spread\"] = df.apply(lambda row: concat_values(row[10], row[11]), axis=1)\n",
    "    df[\"Away Spread\"] = df.apply(lambda row: concat_values(row[12], row[13]), axis=1)\n",
    "    df[\"total_home\"] = df.apply(lambda row: concat_values(row[16], row[17], row[18]), axis=1)\n",
    "    df[\"total_away\"] = df.apply(lambda row: concat_values(row[19], row[20], row[21]), axis=1)\n",
    "\n",
    "    #drop columns\n",
    "    df.drop(columns = [3, 4, 5, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], inplace=True)\n",
    "\n",
    "\n",
    "    columns = [\"date\", \"time\", \"bets\", \"home_team\", \"away_team\", \"home_win\", \"away_win\", \"home_spread\", \"away_spread\", \"total_over\", \"total_under\"]\n",
    "    df.columns = columns\n",
    "\n",
    "    #remove plus from bets\n",
    "    df['bets'] = df['bets'].apply(lambda x: x[2:])\n",
    "\n",
    "    #date operations\n",
    "    #filter data for date\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')  # Adjust the format if needed\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')  # Adjust the format if needed\n",
    "        # Ensure the 'date' column in df is of type datetime.date\n",
    "\n",
    "\n",
    "    # Ensure the 'date' column in df is of type datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    one_week_ago = pd.Timestamp(datetime.today().date() - timedelta(weeks=1))\n",
    "    df['date'].fillna(one_week_ago, inplace=True)\n",
    "\n",
    "    df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "    #create day of the week column\n",
    "    df[\"day\"] = df['date'].dt.strftime('%A')\n",
    "    #set back to string\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Applying the conversion to the 'win_home' and \"Away Win\" columns\n",
    "    df['home_win'] = df['home_win'].apply(convert_to_int)\n",
    "    df[\"away_win\"] = df[\"away_win\"].apply(convert_to_int)\n",
    "    #ranking\n",
    "    home = df[[\"home_team\", 'home_win']].rename(columns={'home_team': 'team', 'home_win': 'odds'})\n",
    "    away = df[['away_team', \"away_win\"]].rename(columns={'away_team': 'team', \"away_win\": 'odds'})\n",
    "    combined = pd.concat([home, away]).sort_values('odds', ascending=False)\n",
    "    combined['index'] = combined.index\n",
    "    combined.index = range(0, 2*len(combined), 2)\n",
    "    df['points'] = None\n",
    "    # Iterating over the combined DataFrame to assign ranks\n",
    "    for i, x in combined.iterrows():\n",
    "        df.at[x['index'], 'points'] = (i-len(combined))/2+1\n",
    "    current_df = df.sort_values('points', ascending=False)\n",
    "    #add game id\n",
    "    current_df[\"game_id\"] = current_df.apply(generate_game_id, axis=1)\n",
    "    #change column order\n",
    "    current_df = current_df[['date', 'day', 'time', 'bets', 'home_team', 'away_team', 'points', 'home_win', 'away_win', 'home_spread', 'away_spread', 'total_over', 'total_under', 'game_id']]\n",
    "    log_data = current_df[['game_id', 'date', 'home_team', 'away_team', 'home_win', 'away_win', 'points']]\n",
    "    log_data_if_changed(log_data)\n",
    "    return current_df\n",
    "\n",
    "def generate_matchups(df):\n",
    "    # Ensure DateTime is properly formatted\n",
    "    df['DateTime'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Sort the DataFrame by DateTime to get matchups from soonest to latest\n",
    "    sorted_df = df.sort_values(by='DateTime')\n",
    "\n",
    "    # Prepare data for the DataTable\n",
    "    matchups_data = []\n",
    "\n",
    "    team_conversion_dict = {\n",
    "    \"Houston Texans\": \"HOU\",\n",
    "    \"New York Jets\": \"NYJ\",\n",
    "    \"Denver Broncos\": \"DEN\",\n",
    "    \"Baltimore Ravens\": \"BAL\",\n",
    "    \"Jacksonville Jaguars\": \"JAX\",\n",
    "    \"Philadelphia Eagles\": \"PHI\",\n",
    "    \"New Orleans Saints\": \"NO\",\n",
    "    \"Carolina Panthers\": \"CAR\",\n",
    "    \"Las Vegas Raiders\": \"LV\",\n",
    "    \"Cincinnati Bengals\": \"CIN\",\n",
    "    \"Miami Dolphins\": \"MIA\",\n",
    "    \"Buffalo Bills\": \"BUF\",\n",
    "    \"Indianapolis Colts\": \"IND\",\n",
    "    \"Minnesota Vikings\": \"MIN\",\n",
    "    \"Washington Commanders\": \"WSH\",\n",
    "    \"New York Giants\": \"NYG\",\n",
    "    \"Detroit Lions\": \"DET\",\n",
    "    \"Green Bay Packers\": \"GB\",\n",
    "    \"New England Patriots\": \"NE\",\n",
    "    \"Tennessee Titans\": \"TEN\",\n",
    "    \"Dallas Cowboys\": \"DAL\",\n",
    "    \"Atlanta Falcons\": \"ATL\",\n",
    "    \"Chicago Bears\": \"CHI\",\n",
    "    \"Arizona Cardinals\": \"ARI\",\n",
    "    \"Los Angeles Chargers\": \"LAC\",\n",
    "    \"Cleveland Browns\": \"CLE\",\n",
    "    \"Los Angeles Rams\": \"LAR\",\n",
    "    \"Seattle Seahawks\": \"SEA\",\n",
    "    \"Tampa Bay Buccaneers\": \"TB\",\n",
    "    \"Kansas City Chiefs\": \"KC\",\n",
    "    'San Francisco 49ers': \"SF\",\n",
    "    'Pittsburgh Steelers': \"PIT\"\n",
    "    }\n",
    "\n",
    "    for _, row in sorted_df.iterrows():\n",
    "        home_team = row['home_team']\n",
    "        away_team = row['away_team']\n",
    "        points = row['points']\n",
    "\n",
    "        # Determine the favored team\n",
    "        projected_winner = home_team if row['home_win'] < row['away_win'] else away_team\n",
    "\n",
    "        # Add row data\n",
    "        matchups_data.append({\n",
    "            \"game_id\": f\"{team_conversion_dict[home_team]}{team_conversion_dict[away_team]}\",\n",
    "            \"matchup\": f\"{home_team} vs {away_team}\",\n",
    "            \"time\": row['DateTime'].strftime('%H:%M %p'),\n",
    "            \"projected_winner\": projected_winner,\n",
    "            \"ranking\": points\n",
    "        })\n",
    "\n",
    "    return matchups_data\n",
    "\n",
    "def get_espn_expert_data():\n",
    "    # Function to transform the game string\n",
    "    def transform_game(game):\n",
    "        try:\n",
    "            teams = game.split(' at ')\n",
    "            return teams[0] + teams[1]\n",
    "        except:\n",
    "            teams = game.split(' VS ')\n",
    "            return teams[0] + teams[1]\n",
    "    try:\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--disable-extensions\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "        options.add_argument(\"--no-sandbox\")  # This line can be important in certain environments\n",
    "        options.set_capability('goog:loggingPrefs', {'browser': 'SEVERE'})\n",
    "        # Initialize the Chrome WebDriver with the specified options\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(\"https://www.espn.com/nfl/picks\")\n",
    "        #time.sleep(10)\n",
    "        driver.implicitly_wait(10)\n",
    "        # get the HTML source\n",
    "        html = driver.page_source\n",
    "        # create a BeautifulSoup object\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # close the driver\n",
    "        driver.quit()\n",
    "\n",
    "        week = soup.find('h1', class_='headline headline__h1 dib').get_text(strip=True).split('- ')[1]\n",
    "\n",
    "        # Extract game details\n",
    "        games = []\n",
    "        game_rows = soup.select('.Table--fixed-left .Table__TBODY .Table__TR')\n",
    "        for row in game_rows:\n",
    "            game_info_element = row.select_one('.wrap-competition a')\n",
    "            game_time_element = row.select_one('.competition-dates')\n",
    "            if game_info_element and game_time_element:\n",
    "                game_info = game_info_element.text\n",
    "                game_time = game_time_element.text\n",
    "                games.append((game_info, game_time))\n",
    "\n",
    "        # Extract expert names\n",
    "        experts = []\n",
    "        expert_headers = soup.select('.Table__Scroller .Table__THEAD .Table__TH')\n",
    "        for header in expert_headers:\n",
    "            expert_name_element = header.select_one('div')\n",
    "            if expert_name_element:\n",
    "                expert_name = expert_name_element.text.strip()\n",
    "                experts.append(expert_name)\n",
    "\n",
    "        # Extract picks\n",
    "        picks = []\n",
    "        pick_rows = soup.select('.Table__Scroller .Table__TBODY .Table__TR')\n",
    "        for row in pick_rows:\n",
    "            pick_row = []\n",
    "            pick_cells = row.select('.Table__TD')\n",
    "            for cell in pick_cells:\n",
    "                team_logo = cell.select_one('img')\n",
    "                if team_logo:\n",
    "                    # Extract the team abbreviation from the image URL\n",
    "                    team = team_logo['src'].split('/')[-1].split('.')[0]\n",
    "                else:\n",
    "                    team = None\n",
    "                pick_row.append(team)\n",
    "            picks.append(pick_row)\n",
    "\n",
    "        # Create DataFrame\n",
    "        data = {'Game': [game[0] for game in games], 'Time': [game[1] for game in games]}\n",
    "        for i, expert in enumerate(experts):\n",
    "            data[expert] = [pick[i] for pick in picks]\n",
    "\n",
    "        data['Game'].append(None)\n",
    "        data['Time'].append(None)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.dropna(subset=[\"Game\"], inplace=True)\n",
    "\n",
    "        df['week'] = week\n",
    "\n",
    "        convert_dict = {\n",
    "            \"min\": \"Vikings\", \"phi\": \"Eagles\", \"bal\": \"Ravens\", \"det\": \"Lions\", \"mia\": \"Dolphins\",\n",
    "            \"nyj\": \"Jets\", \"atl\": \"Falcons\", \"gb\": \"Packers\", \"hou\" : \"Texans\", \"lac\": \"Chargers\",\n",
    "            \"buf\": \"Bills\", \"den\": \"Broncos\", \"kc\": \"Chiefs\", \"chi\": \"Bears\", \"sf\": \"49ers\", \"pit\": \"Steelers\",\n",
    "            \"no\": \"Saints\", \"cin\": \"Bengals\", \"ne\": \"Patriots\", \"wsh\": \"Commanders\", \"ari\": \"Cardinals\", \n",
    "            \"lar\": \"Rams\"\n",
    "        }\n",
    "\n",
    "        for ix, row in df.iterrows():\n",
    "            values = row.to_list()[2:]\n",
    "            values = [value for value in values if value is not None]\n",
    "            values_len = len(values)\n",
    "            values_dict = {}\n",
    "            for value in values:\n",
    "                if value not in values_dict.keys():\n",
    "                    values_dict[value] = 1\n",
    "                else:\n",
    "                    values_dict[value] += 1\n",
    "            #sorting\n",
    "            values_dict = dict(sorted(values_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "            top_key = next(iter(values_dict))\n",
    "            if top_key in convert_dict:\n",
    "                converted_key = convert_dict[top_key]\n",
    "            else:\n",
    "                converted_key = top_key\n",
    "            pct = int(values_dict[top_key]/values_len*100)\n",
    "            message = f\"{pct}% of experts chose {converted_key}\"\n",
    "            df.loc[ix, \"pct\"] = pct\n",
    "            df.loc[ix, \"message\"] = message\n",
    "\n",
    "        df[\"game_id\"] = df[\"Game\"].apply(transform_game)\n",
    "        return df[[\"game_id\", \"week\", \"Game\", \"Time\", \"pct\", \"message\"]]\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"get espn data, {e}\")\n",
    "\n",
    "def get_start_end():\n",
    "    today = datetime.now()\n",
    "    weekday = today.weekday()  # Monday is 0 and Sunday is 6\n",
    "\n",
    "    # Calculate the start date (Tuesday)\n",
    "    if weekday >= 1:  # If today is Tuesday or after\n",
    "        start_date = today - timedelta(days=(weekday - 1))\n",
    "    else:  # If today is before Tuesday\n",
    "        start_date = today - timedelta(days=(weekday + 6))\n",
    "\n",
    "    # Calculate the end date (Monday)\n",
    "    if weekday <= 0:  # If today is Monday\n",
    "        end_date = today\n",
    "    else:  # If today is after Monday\n",
    "        end_date = today + timedelta(days=(7 - weekday))\n",
    "    return start_date, end_date\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Bovada and ESPN Expert Data\"),\n",
    "    dcc.Interval(\n",
    "        id='interval-component',\n",
    "        interval=1*60*1000,  # in milliseconds (1 minute)\n",
    "        n_intervals=0\n",
    "    ),\n",
    "    html.Div(id='data-table')\n",
    "])\n",
    "\n",
    "@app.callback(Output('data-table', 'children'),\n",
    "              [Input('interval-component', 'n_intervals')])\n",
    "def update_table(n):\n",
    "    # Your script logic here\n",
    "    start, end = get_start_end()\n",
    "    bovada_df = get_data(start, end)\n",
    "    matchup_df = pd.DataFrame(generate_matchups(bovada_df)).sort_values(\"ranking\", ascending=False)\n",
    "    expert_df = get_espn_expert_data()\n",
    "    expert_df.sort_values(\"pct\", ascending=False)\n",
    "    merged_df = pd.merge(matchup_df, expert_df, on=\"game_id\")\n",
    "    merged_df.drop(columns=[\"game_id\", \"time\", \"pct\", \"matchup\"], inplace=True)\n",
    "    merged_df[\"IngestTime\"] = datetime.now().strftime(\"%m/%d %H:%M\")\n",
    "    merged_df = merged_df[[\"IngestTime\", \"week\", \"Game\", \"Time\", \"projected_winner\", \"ranking\", \"message\"]]\n",
    "    merged_df[\"ranking\"] = merged_df[\"ranking\"]+1\n",
    "\n",
    "    return html.Table([\n",
    "        html.Thead(\n",
    "            html.Tr([html.Th(col) for col in merged_df.columns])\n",
    "        ),\n",
    "        html.Tbody([\n",
    "            html.Tr([\n",
    "                html.Td(merged_df.iloc[i][col]) for col in merged_df.columns\n",
    "            ]) for i in range(len(merged_df))\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
